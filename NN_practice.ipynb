{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/luke/Desktop/kaggle/Home_Credit_Default_Risk')\n",
    "x_val = pd.read_csv('x_val.csv')\n",
    "y_val = pd.read_csv('y_val.csv')\n",
    "partial_y_train = pd.read_csv('partial_y_train.csv')\n",
    "partial_x_train = pd.read_csv('partial_x_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (239999, 239)\n",
      "Training label shape:  (239999, 1)\n",
      "Validation data shape:  (67510, 239)\n",
      "Validation label shape:  (67510, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: ', partial_x_train.shape)\n",
    "print('Training label shape: ', partial_y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation label shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.197455179324805385e-01</th>\n",
       "      <th>0.000000000000000000e+00</th>\n",
       "      <th>1.000000000000000000e+00</th>\n",
       "      <th>0.000000000000000000e+00.1</th>\n",
       "      <th>5.263157894736841813e-02</th>\n",
       "      <th>2.454384230388970047e-03</th>\n",
       "      <th>5.693483146067415679e-02</th>\n",
       "      <th>5.533520533520533413e-02</th>\n",
       "      <th>4.377104377104376609e-02</th>\n",
       "      <th>1.560552770777368613e-02</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000000000000000000e+00.154</th>\n",
       "      <th>0.000000000000000000e+00.155</th>\n",
       "      <th>0.000000000000000000e+00.156</th>\n",
       "      <th>0.000000000000000000e+00.157</th>\n",
       "      <th>0.000000000000000000e+00.158</th>\n",
       "      <th>0.000000000000000000e+00.159</th>\n",
       "      <th>0.000000000000000000e+00.160</th>\n",
       "      <th>0.000000000000000000e+00.161</th>\n",
       "      <th>0.000000000000000000e+00.162</th>\n",
       "      <th>0.000000000000000000e+00.163</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.126730</td>\n",
       "      <td>0.094068</td>\n",
       "      <td>0.108866</td>\n",
       "      <td>0.157398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.061495</td>\n",
       "      <td>0.057239</td>\n",
       "      <td>0.093190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.219760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.236725</td>\n",
       "      <td>0.158301</td>\n",
       "      <td>0.217733</td>\n",
       "      <td>0.134897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.388515</td>\n",
       "      <td>0.158915</td>\n",
       "      <td>0.346801</td>\n",
       "      <td>0.129705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.119333</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.309272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2.197455179324805385e-01  0.000000000000000000e+00  \\\n",
       "0                  0.219751                       0.0   \n",
       "1                  0.219757                       0.0   \n",
       "2                  0.219760                       0.0   \n",
       "3                  0.219762                       0.0   \n",
       "4                  0.219765                       0.0   \n",
       "\n",
       "   1.000000000000000000e+00  0.000000000000000000e+00.1  \\\n",
       "0                       0.0                         0.0   \n",
       "1                       0.0                         1.0   \n",
       "2                       0.0                         1.0   \n",
       "3                       1.0                         1.0   \n",
       "4                       1.0                         1.0   \n",
       "\n",
       "   5.263157894736841813e-02  2.454384230388970047e-03  \\\n",
       "0                  0.000000                  0.002089   \n",
       "1                  0.105263                  0.001166   \n",
       "2                  0.052632                  0.000935   \n",
       "3                  0.000000                  0.002281   \n",
       "4                  0.000000                  0.001320   \n",
       "\n",
       "   5.693483146067415679e-02  5.533520533520533413e-02  \\\n",
       "0                  0.126730                  0.094068   \n",
       "1                  0.056180                  0.061495   \n",
       "2                  0.236725                  0.158301   \n",
       "3                  0.388515                  0.158915   \n",
       "4                  0.119333                  0.098333   \n",
       "\n",
       "   4.377104377104376609e-02  1.560552770777368613e-02  \\\n",
       "0                  0.108866                  0.157398   \n",
       "1                  0.057239                  0.093190   \n",
       "2                  0.217733                  0.134897   \n",
       "3                  0.346801                  0.129705   \n",
       "4                  0.098765                  0.309272   \n",
       "\n",
       "               ...               0.000000000000000000e+00.154  \\\n",
       "0              ...                                        0.0   \n",
       "1              ...                                        0.0   \n",
       "2              ...                                        0.0   \n",
       "3              ...                                        0.0   \n",
       "4              ...                                        0.0   \n",
       "\n",
       "   0.000000000000000000e+00.155  0.000000000000000000e+00.156  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   0.000000000000000000e+00.157  0.000000000000000000e+00.158  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   0.000000000000000000e+00.159  0.000000000000000000e+00.160  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           1.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           1.0                           0.0   \n",
       "\n",
       "   0.000000000000000000e+00.161  0.000000000000000000e+00.162  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           1.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           1.0   \n",
       "\n",
       "   0.000000000000000000e+00.163  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_use = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48743, 239)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the training and testing data \n",
    "train = np.array(application_train.drop(columns = 'TARGET'))\n",
    "test = np.array(application_test)\n",
    "\n",
    "train_labels = np.array(train_labels).reshape((-1, ))\n",
    "\n",
    "# 10 fold cross validation\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=50)\n",
    "\n",
    "# Validation and test predictions\n",
    "valid_preds = np.zeros(train.shape[0])\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "\n",
    "# Iterate through each fold\n",
    "for n_fold, (train_indices, valid_indices) in enumerate(folds.split(train)):\n",
    "    # Training data for the fold\n",
    "    train_fold, train_fold_labels = train[train_indices, :], train_labels[train_indices]\n",
    "    \n",
    "    # Validation data for the fold\n",
    "    valid_fold, valid_fold_labels = train[valid_indices, :], train_labels[valid_indices]\n",
    "    \n",
    "    # LightGBM classifier with hyperparameters\n",
    "    clf = LGBMClassifier(\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.1,\n",
    "        subsample=.8,\n",
    "        max_depth=7,\n",
    "        reg_alpha=.1,\n",
    "        reg_lambda=.1,\n",
    "        min_split_gain=.01,\n",
    "        min_child_weight=2\n",
    "    )\n",
    "    \n",
    "    # Fit on the training data, evaluate on the validation data\n",
    "    clf.fit(train_fold, train_fold_labels, \n",
    "            eval_set= [(train_fold, train_fold_labels), (valid_fold, valid_fold_labels)], \n",
    "            eval_metric='auc', early_stopping_rounds=100, verbose = False\n",
    "           )\n",
    "    \n",
    "    # Validation preditions\n",
    "    valid_preds[valid_indices] = clf.predict_proba(valid_fold, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    \n",
    "    # Testing predictions\n",
    "    test_preds += clf.predict_proba(test, num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "    \n",
    "    # Display the performance for the current fold\n",
    "    print('Fold %d AUC : %0.6f' % (n_fold + 1, roc_auc_score(valid_fold_labels, valid_preds[valid_indices])))\n",
    "    \n",
    "    # Delete variables to free up memory\n",
    "    del clf, train_fold, train_fold_labels, valid_fold, valid_fold_labels\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "# Make a submission dataframe\n",
    "#submission = application_test[['SK_ID_CURR']]\n",
    "#submission['TARGET'] = test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239999, 239)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(unit,epochs,batch_size):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, input_shape=(239,)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(partial_x_train,partial_y_train, epochs=20, verbose=0,batch_size=100,validation_data=(x_val, y_val))\n",
    "    y_pred = model.predict_proba(x_test_use)\n",
    "    return roc_auc_score(y_val, model.predict_proba(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.4 s, sys: 2.75 s, total: 50.1 s\n",
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer, init):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, kernel_initializer=init, input_shape=(239,)))\n",
    "    model.add(layers.Dense(64, kernel_initializer=init, activation='relu'))\n",
    "    model.add(layers.Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "    return(model)\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, epochs = 2, batch_size = 5000)\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal']\n",
    "# epochs = [5,10]\n",
    "# batches = [1000,5000]\n",
    "param_grid = dict(optimizer = optimizers, init = init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc')\n",
    "grid_result = grid.fit(partial_x_train, partial_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.704093 using {'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.704093 (0.007345) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.658728 (0.006197) with: {'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.660480 (0.003081) with: {'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.609402 (0.003451) with: {'init': 'uniform', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, input_shape=(239,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 239999 samples, validate on 67510 samples\n",
      "Epoch 1/20\n",
      "239999/239999 [==============================] - 5s 21us/step - loss: 0.2579 - acc: 0.9189 - val_loss: 0.2517 - val_acc: 0.9195\n",
      "Epoch 2/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2528 - acc: 0.9193 - val_loss: 0.2505 - val_acc: 0.9196\n",
      "Epoch 3/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2517 - acc: 0.9193 - val_loss: 0.2517 - val_acc: 0.9196\n",
      "Epoch 4/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2511 - acc: 0.9193 - val_loss: 0.2509 - val_acc: 0.9194\n",
      "Epoch 5/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2509 - acc: 0.9193 - val_loss: 0.2506 - val_acc: 0.9190\n",
      "Epoch 6/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2503 - acc: 0.9194 - val_loss: 0.2506 - val_acc: 0.9193\n",
      "Epoch 7/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2501 - acc: 0.9195 - val_loss: 0.2515 - val_acc: 0.9194\n",
      "Epoch 8/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2491 - acc: 0.9196 - val_loss: 0.2552 - val_acc: 0.9165\n",
      "Epoch 9/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2486 - acc: 0.9197 - val_loss: 0.2515 - val_acc: 0.9184\n",
      "Epoch 10/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2481 - acc: 0.9198 - val_loss: 0.2514 - val_acc: 0.9191\n",
      "Epoch 11/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2477 - acc: 0.9198 - val_loss: 0.2511 - val_acc: 0.9190\n",
      "Epoch 12/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2470 - acc: 0.9199 - val_loss: 0.2528 - val_acc: 0.9188\n",
      "Epoch 13/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2463 - acc: 0.9202 - val_loss: 0.2523 - val_acc: 0.9185\n",
      "Epoch 14/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2458 - acc: 0.9202 - val_loss: 0.2524 - val_acc: 0.9187\n",
      "Epoch 15/20\n",
      "239999/239999 [==============================] - 5s 21us/step - loss: 0.2452 - acc: 0.9203 - val_loss: 0.2532 - val_acc: 0.9186\n",
      "Epoch 16/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2447 - acc: 0.9206 - val_loss: 0.2547 - val_acc: 0.9185\n",
      "Epoch 17/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2440 - acc: 0.9204 - val_loss: 0.2558 - val_acc: 0.9178\n",
      "Epoch 18/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2432 - acc: 0.9208 - val_loss: 0.2554 - val_acc: 0.9186\n",
      "Epoch 19/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2425 - acc: 0.9210 - val_loss: 0.2562 - val_acc: 0.9186\n",
      "Epoch 20/20\n",
      "239999/239999 [==============================] - 5s 20us/step - loss: 0.2424 - acc: 0.9209 - val_loss: 0.2552 - val_acc: 0.9181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f306578b160>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(partial_x_train,partial_y_train, epochs=20, batch_size=100,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31712615],\n",
       "       [0.05558179],\n",
       "       [0.04675853],\n",
       "       ...,\n",
       "       [0.05032958],\n",
       "       [0.0774654 ],\n",
       "       [0.11556797]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(x_test_use)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327954279091746"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_val, model.predict_proba(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() got an unexpected keyword argument 'kernel_regularizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5806a0d0cb85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m239\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.compile(optimizer='rmsprop',\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add() got an unexpected keyword argument 'kernel_regularizer'"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, input_shape=(239,)),kernel_regularizer=regularizers.l2(0.01))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,partial_y_train,epochs = 10,batch_size=100000,validation_data = (x_val,y_val),verbose = 1)\n",
    "y_pred = model.predict_proba(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
